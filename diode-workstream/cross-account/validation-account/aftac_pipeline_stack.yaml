Parameters:
  IamPrefix:
    Type: String
    Description: Prefix added to all IAM resources

  PermissionsBoundaryPolicyArn:
    Type: String
    Description: ARN of the policy that is used to set the permissions boundary for IAM resources

  ResourceSuffix:
    Type: String
    Description: Suffix added to the named AWS resources

  VpcId:
    Type: String
    Description: The VPC ID to use for the pipeline

  VpcCidr:
    Type: String
    Description: The CIDR block of the existing VPC

  PrivateSubnetIds:
    Type: CommaDelimitedList
    Description: The list of private subnet IDs to use for the pipeline

  S3PrefixListId:
    Type: String
    Description: The S3 prefix list ID to use for the pipeline

  DDBPrefixListId:
    Type: String
    Description: The DDB prefix list ID to use for the pipeline

  PipelineAmiId:
    Type: AWS::EC2::Image::Id
    Description: The AMI ID to use for the pipeline
    AllowedPattern: ^ami-[0-9a-f]{17}$
    ConstraintDescription: Must be a valid AMI ID

  ApprovedFileTypes:
    Type: String
    Description: The list of approved file types

  DfdlApprovedFileTypes:
    Type: String
    Description: The list of approved file types for DFDL

  DiodeAccountId:
    Type: String
    Description: AWS Account ID of the Diode Account
    AllowedPattern: ^\d{12}$
    ConstraintDescription: Must be a valid AWS Account ID

  DiodeSimulatorInstanceRole:
    Type: String
    Description: ARN of the IAM role associated with the Diode Simulator instance profile

  TranstionToGlacierIR:
    Type: Number
    Description: Enter the number of days after which to transition to Glacier Instant Retrieval (IR) storage class.

  TransitionToDeepArchive:
    Type: Number
    Description: Enter the number of days after which to transition to Deep Archive storage class. Must be at least 90 days after Glacier IR transition.

  InvalidFilesBucketExpirationInDays:
    Type: Number
    Description: Enter the number of days you want to keep objects in the INVALID FILES Bucket.

  FailedTransferBucketExpirationInDays:
    Type: Number
    Description: Enter the number of days you want to keep objects in the FAILED TRANSFER Bucket.

  DataTransferBucketExpirationInDays:
    Type: Number
    Description: Enter the number of days you want to keep objects in the DATA TRANSFER Bucket.

Conditions:
  UseDiodeSimulator: !Not [!Equals [!Ref DiodeSimulatorInstanceRole, ""]]

Resources:
  Ec2ScannerRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: An explicit name is required
    Properties:
      # Note that there is a dependency on this name
      RoleName: !Sub ${IamPrefix}-Ec2ScannerRole-${ResourceSuffix}
      PermissionsBoundary: !Ref PermissionsBoundaryPolicyArn
      Description: Role to be assumed by EC2 Anti-Virus Scanner instances
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/AmazonSSMManagedInstanceCore
      Policies:
        - PolicyName: Ec2ScannerCwLogsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:DescribeLogStreams
                  - logs:PutLogEvents
                  - logs:PutRetentionPolicy
                  - cloudwatch:PutMetricData
                Effect: Allow
                Resource: "*"
        - PolicyName: Ec2ScannerSqsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - sqs:DeleteMessage
                  - sqs:ReceiveMessage
                  - sqs:SendMessage
                  - sqs:ChangeMessageVisibility
                Resource: !Sub arn:${AWS::Partition}:sqs:${AWS::Region}:${AWS::AccountId}:*
        - PolicyName: Ec2ScannerS3Policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - s3:DeleteObject
                  - s3:GetBucketAcl
                  - s3:GetObject
                  - s3:GetObjectTagging
                  - s3:ListBucket
                  - s3:PutObject
                  - s3:PutObjectTagging
                Resource: "*"
        - PolicyName: Ec2ScannerSnsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: sns:Publish
                Resource: "*"
        - PolicyName: Ec2ScannerEc2Policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: ec2:DescribeTags
                Resource: "*"

  Ec2ScannerInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      InstanceProfileName: !Sub ${IamPrefix}-Ec2ScannerInstanceProfile-${ResourceSuffix}
      Roles: [!Ref Ec2ScannerRole]

  TransferResultLambdaRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: An explicit name is required
    Properties:
      RoleName: !Sub ${IamPrefix}-TransferResultLambdaRole-${ResourceSuffix}
      PermissionsBoundary: !Ref PermissionsBoundaryPolicyArn
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: TransferResultLambdaRoleDefaultPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              # Security best practice: https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#configuration-vpc-best-practice-security
              - Effect: Deny
                Action:
                  - ec2:CreateNetworkInterface
                  - ec2:DeleteNetworkInterface
                  - ec2:DescribeNetworkInterfaces
                  - ec2:DescribeSubnets
                  - ec2:DetachNetworkInterface
                  - ec2:AssignPrivateIpAddresses
                  - ec2:UnassignPrivateIpAddresses
                Resource: "*"
                Condition:
                  ArnEquals:
                    lambda:SourceFunctionArn: !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:${AWS::AccountId}:function:transfer-result-recorder-${ResourceSuffix}
              - Effect: Allow
                Action:
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                  - sqs:ReceiveMessage
                Resource: !Sub arn:${AWS::Partition}:sqs:${AWS::Region}:${AWS::AccountId}:*
              - Effect: Allow
                Action: sns:Publish
                Resource: !Sub arn:${AWS::Partition}:sns:${AWS::Region}:${AWS::AccountId}:*
              - Effect: Allow
                Action: dynamodb:PutItem
                Resource: !Sub arn:${AWS::Partition}:dynamodb:${AWS::Region}:${AWS::AccountId}:*
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:GetObjectTagging
                  - s3:PutObject
                  - s3:PutObjectTagging
                  - s3:DeleteObject
                  - s3:GetBucketAcl
                  - s3:ListBucket
                Resource: !Sub arn:${AWS::Partition}:s3:::*

  TransferResultLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58 # Lambda functions require permission to write CloudWatch Logs
            reason: The managed policy, AWSLambdaVPCAccessExecutionRole, attached to the execution role includes permissions to write to CloudWatch Logs
    Properties:
      FunctionName: !Sub transfer-result-recorder-${ResourceSuffix}
      Handler: index.lambda_handler
      Role: !GetAtt TransferResultLambdaRole.Arn
      Runtime: python3.11
      Timeout: 15
      # LoggingConfig:
      #   LogGroup: The name of the log group
      # ReservedConcurrentExecutions: 50
      Environment:
        Variables:
          FAILED_TRANSFER_TOPIC_ARN: !GetAtt FailedTransferTopic.TopicArn
          DATA_TRANSFER_BUCKET: !Ref DataTransferBucket
          DYNAMODB_TABLE_NAME: !Ref TransferStatusTable
          FAILED_TRANSFER_BUCKET: !Ref FailedTransferBucket
          ACCOUNT_ID: !Ref AWS::AccountId
      VpcConfig:
        SecurityGroupIds:
          - !Ref LambdaFunctionsSecurityGroup
        SubnetIds: !Ref PrivateSubnetIds
      Code:
        ZipFile: |
          import json
          import logging
          import os
          import zoneinfo
          from datetime import datetime

          import boto3  # type: ignore
          from botocore.config import Config  # type: ignore
          from botocore.exceptions import ClientError  # type: ignore

          DDB_TABLE_NAME = os.environ["DYNAMODB_TABLE_NAME"]
          DATA_TRANSFER_BUCKET = os.environ["DATA_TRANSFER_BUCKET"]
          FAILED_TRANSFER_TOPIC_ARN = os.environ["FAILED_TRANSFER_TOPIC_ARN"]
          FAILED_TRANSFER_BUCKET = os.environ["FAILED_TRANSFER_BUCKET"]
          ACCOUNT_ID = os.environ["ACCOUNT_ID"]

          DATA_TAG_KEY = "DataOwner / DataSteward / GovPOC / KeyOwner"
          UNKNOWNS = ["Unknown"] * 4

          config = Config(retries={"max_attempts": 5, "mode": "standard"})
          DDB_CLIENT = boto3.client("dynamodb", config=config)
          S3_CLIENT = boto3.client("s3", config=config)
          SNS_CLIENT = boto3.client("sns", config=config)

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)


          def lambda_handler(event, context):
              logger.info(f"Event: {json.dumps(event, default=str)}")

              data = json.loads(event["Records"][0]["body"])
              bucket = data["bucket"]
              key = data["key"]
              status = data["status"]

              data_tag_values = get_data_tag_values(bucket, key)
              put_item_in_ddb(data, *data_tag_values)

              if status != "SUCCEEDED":
                  logger.info(
                      f"Data transfer failed; copying {bucket}/{key} to {FAILED_TRANSFER_BUCKET}",  # noqa: E501
                  )
                  # Copy the failed S3 object to the failed transfer bucket
                  copy_object(DATA_TRANSFER_BUCKET, FAILED_TRANSFER_BUCKET, key)
                  # Send a message to the SNS topic for failed data transfers
                  send_transfer_error_message(key)

              delete_object(DATA_TRANSFER_BUCKET, key)


          def get_data_tag_values(bucket: str, key: str) -> list[str]:
              """
              Returns values for tag key `DataOwner / DataSteward / GovPOC / KeyOwner`
              as individual values in a list.\n
              If the tag is not set, returns "Unknown" x 4 in a list.
              """
              logger.info(f"Getting tags for {bucket}/{key}")
              try:
                  tags = get_object_tags(bucket, key)
                  data_tag_value = tags.get(DATA_TAG_KEY)
                  if data_tag_value is None:
                      logger.warning(f"The object did not have {DATA_TAG_KEY} tag key")
                      return UNKNOWNS
                  logger.info("Successfully retrieved the data tag value")
                  return [tag.strip() for tag in data_tag_value.split("/")]
              except ClientError as e:
                  logger.error(f"Failed to get object tags: {e}")
                  return UNKNOWNS


          def get_object_tags(bucket: str, key: str) -> dict[str, str]:
              """
              Returns `TagSet` for `key` in `bucket` in a dict.
              """
              tag_set = S3_CLIENT.get_object_tagging(
                  Bucket=bucket,
                  Key=key,
                  ExpectedBucketOwner=ACCOUNT_ID,
              )["TagSet"]

              tags = {tag["Key"]: tag["Value"] for tag in tag_set}
              logger.info(f"Tags for {bucket}/{key}: {tags}")
              return tags


          def put_item_in_ddb(
              data: dict,
              data_owner: str,
              data_steward: str,
              gov_poc: str,
              key_owner: str,
          ):
              s3_key = data["key"]
              logger.info(f"Adding an entry into DynamoDB on the transfer status of {s3_key}")
              DDB_CLIENT.put_item(
                  TableName=DDB_TABLE_NAME,
                  Item={
                      "s3Key": {"S": s3_key},  # partition key
                      "timestamp": {
                          "S": str(
                              datetime.now(zoneinfo.ZoneInfo("America/New_York")),  # sort key
                          ),
                      },
                      "mappingId": {"S": data["mappingId"]},
                      "status": {"S": data["status"]},
                      "transferId": {"S": data["transferId"]},
                      "dataOwner": {"S": data_owner},
                      "dataSteward": {"S": data_steward},
                      "govPoc": {"S": gov_poc},
                      "keyOwner": {"S": key_owner},
                  },
              )
              logger.info("Successfully added the entry")


          def send_transfer_error_message(key: str):
              logger.info("Sending an SNS message regarding the failed transfer")
              SNS_CLIENT.publish(
                  TopicArn=FAILED_TRANSFER_TOPIC_ARN,
                  Subject="Failed Cross Domain Transfer",
                  Message=(
                      f"The file {key} was NOT successfully transferred.\n"
                      "It has been moved from the Data Transfer bucket to "
                      f"the following location:\n{FAILED_TRANSFER_BUCKET}/{key}"
                  ),
              )


          def copy_object(src_bucket: str, dest_bucket: str, key: str):
              logger.info(f"Copying {src_bucket}/{key} to {dest_bucket}/{key}")
              S3_CLIENT.copy_object(
                  # Source bucket/key/owner
                  CopySource={"Bucket": src_bucket, "Key": key},
                  ExpectedSourceBucketOwner=ACCOUNT_ID,
                  # Destination bucket/key/owner
                  Bucket=dest_bucket,
                  Key=key,
                  ExpectedBucketOwner=ACCOUNT_ID,
              )
              logger.info("Successfully copied the object")


          def delete_object(bucket: str, key: str):
              logger.info(f"Deleting {bucket}/{key}")
              S3_CLIENT.delete_object(
                  Bucket=bucket,
                  Key=key,
                  ExpectedBucketOwner=ACCOUNT_ID,
              )
              logger.info("Successfully deleted the object")

  QuarantineBucket:
    Type: AWS::S3::Bucket
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      LoggingConfiguration:
        DestinationBucketName:
          Fn::ImportValue: !Sub access-logs-bucket-${ResourceSuffix}
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  QuarantineBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref QuarantineBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal:
              AWS: "*"
            Action: s3:*
            Resource:
              - !Sub ${QuarantineBucket.Arn}
              - !Sub ${QuarantineBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false

  InvalidFilesBucket:
    Type: AWS::S3::Bucket
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      LoggingConfiguration:
        DestinationBucketName:
          Fn::ImportValue: !Sub access-logs-bucket-${ResourceSuffix}
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: LifeCycleRule-1
            Status: Enabled
            Transitions:
              - TransitionInDays: !Ref TranstionToGlacierIR
                StorageClass: GLACIER_IR
              - TransitionInDays: !Ref TransitionToDeepArchive
                StorageClass: DEEP_ARCHIVE
            ExpirationInDays: !Ref InvalidFilesBucketExpirationInDays
            NoncurrentVersionExpiration:
              NoncurrentDays: 1

  InvalidFilesBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref InvalidFilesBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal:
              AWS: "*"
            Action: s3:*
            Resource:
              - !Sub ${InvalidFilesBucket.Arn}
              - !Sub ${InvalidFilesBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false

  FailedTransferBucket:
    Type: AWS::S3::Bucket
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      LoggingConfiguration:
        DestinationBucketName:
          Fn::ImportValue: !Sub access-logs-bucket-${ResourceSuffix}
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: LifeCycleRule-1
            Status: Enabled
            Transitions:
              - TransitionInDays: !Ref TranstionToGlacierIR
                StorageClass: GLACIER_IR
              - TransitionInDays: !Ref TransitionToDeepArchive
                StorageClass: DEEP_ARCHIVE
            ExpirationInDays: !Ref FailedTransferBucketExpirationInDays
            NoncurrentVersionExpiration:
              NoncurrentDays: 1

  FailedTransferBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref FailedTransferBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal:
              AWS: "*"
            Action: s3:*
            Resource:
              - !Sub ${FailedTransferBucket.Arn}
              - !Sub ${FailedTransferBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false

  DataTransferBucket:
    Type: AWS::S3::Bucket
    DependsOn: TransferQueuePolicy
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      LoggingConfiguration:
        DestinationBucketName:
          Fn::ImportValue: !Sub access-logs-bucket-${ResourceSuffix}
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      NotificationConfiguration:
        QueueConfigurations:
          - Event: s3:ObjectCreated:*
            Queue: !GetAtt TransferQueue.Arn
      LifecycleConfiguration:
        Rules:
          - Id: LifeCycleRule-1
            Status: Enabled
            Transitions:
              - TransitionInDays: !Ref TranstionToGlacierIR
                StorageClass: GLACIER_IR
              - TransitionInDays: !Ref TransitionToDeepArchive
                StorageClass: DEEP_ARCHIVE
            ExpirationInDays: !Ref DataTransferBucketExpirationInDays
            NoncurrentVersionExpiration:
              NoncurrentDays: 1

  DataTransferBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref DataTransferBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal: "*"
            Action: s3:*
            Resource:
              - !Sub ${DataTransferBucket.Arn}
              - !Sub ${DataTransferBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false
          - Effect: Allow
            Principal:
              AWS: !Ref DiodeAccountId
            Action:
              - s3:GetObject
              - s3:GetObjectTagging
            Resource: !Sub ${DataTransferBucket.Arn}/*
            Condition:
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${DiodeAccountId}:role/${IamPrefix}-DataTransferLambdaRole-${ResourceSuffix}
          - !If
            - UseDiodeSimulator
            - Sid: AllowS3PermissionsForDiodeSimulatorInstance
              Effect: Allow
              Principal:
                AWS: !Ref DiodeSimulatorInstanceRole
              Action:
                - s3:GetObject
                - s3:GetObjectTagging
              Resource: !Sub ${DataTransferBucket.Arn}/*
            - !Ref AWS::NoValue

  LambdaFunctionsSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security Group for Lambda Functions
      SecurityGroupEgress:
        - CidrIp: !Ref VpcCidr
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to VPC CIDR
        - DestinationPrefixListId: !Ref S3PrefixListId
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to S3 Gateway Endpoint
        - DestinationPrefixListId: !Ref DDBPrefixListId
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to DDB Gateway Endpoint
      VpcId: !Ref VpcId

  AvScanSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security Group for Pipeline EC2 instances
      SecurityGroupEgress:
        - CidrIp: !Ref VpcCidr
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to VPC CIDR
        - DestinationPrefixListId: !Ref S3PrefixListId
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to S3 Gateway Endpoint
      VpcId: !Ref VpcId

  InfectedFileTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Infected File SNS Topic
      KmsMasterKeyId: alias/aws/sns

  InvalidFilesTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Invalid File SNS Topic
      KmsMasterKeyId: alias/aws/sns

  AutoScalingGroupLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        IamInstanceProfile:
          Arn: !GetAtt Ec2ScannerInstanceProfile.Arn
        ImageId: !Ref PipelineAmiId
        InstanceType: m5.large
        Monitoring:
          Enabled: false
        MetadataOptions:
          HttpPutResponseHopLimit: 1
          HttpTokens: required
        SecurityGroupIds:
          - !GetAtt AvScanSecurityGroup.GroupId
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub ValidationPipeline/ValidationInstance-${ResourceSuffix}
      TagSpecifications:
        - ResourceType: launch-template
          Tags:
            - Key: Name
              Value: !Sub ValidationPipeline/LaunchTemplate-${ResourceSuffix}

  PipelineAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    UpdatePolicy:
      AutoScalingScheduledAction:
        IgnoreUnmodifiedGroupSizeProperties: true
    Properties:
      LaunchTemplate:
        LaunchTemplateId: !Ref AutoScalingGroupLaunchTemplate
        # TODO: Determine if we need to set this to Default using an API
        Version: !GetAtt AutoScalingGroupLaunchTemplate.DefaultVersionNumber
      MaxSize: "12"
      MinSize: "2"
      VPCZoneIdentifier: !Ref PrivateSubnetIds
      Tags:
        - Key: Name
          PropagateAtLaunch: false
          Value: !Sub ValidationPipeline/AutoScalingGroup-${ResourceSuffix}

  AsgScaleUpAction:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AdjustmentType: ChangeInCapacity
      AutoScalingGroupName: !Ref PipelineAutoScalingGroup
      EstimatedInstanceWarmup: 120
      MetricAggregationType: Average
      PolicyType: StepScaling
      StepAdjustments:
        - MetricIntervalLowerBound: 0
          ScalingAdjustment: 1

  AsgScaleDownAction:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AdjustmentType: ChangeInCapacity
      AutoScalingGroupName: !Ref PipelineAutoScalingGroup
      EstimatedInstanceWarmup: 120
      MetricAggregationType: Average
      PolicyType: StepScaling
      StepAdjustments:
        - MetricIntervalUpperBound: -10
          ScalingAdjustment: -1

  SetDefaultLaunchTemplateTrigger:
    Type: Custom::SetDefaultLaunchTemplateTrigger
    Properties:
      ServiceToken: !GetAtt SetDefaultLaunchTemplateLambdaFunction.Arn
      ServiceTimeout: "120"
      AutoScalingGroupname: !Ref PipelineAutoScalingGroup
      LaunchTemplateId: !Ref AutoScalingGroupLaunchTemplate

  SetDefaultLaunchTemplateLambdaFunction:
    Type: AWS::Lambda::Function
    Metadata:
      checkov:
        skip:
          - id: CKV_AWS_116 # Ensure that AWS Lambda function is configured for a Dead Letter Queue(DLQ)
            comment: Invoked by CloudFormation, the function surfaces any errors through the stack, without the need for a DLQ
          - id: CKV_AWS_117 # Ensure that AWS Lambda function is configured inside a VPC
            comment: This function is not required to be deployed inside a VPC
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: This function is not required to be deployed inside a VPC
          - id: W58 # Lambda functions require permission to write CloudWatch Logs
            reason: The execution role includes permissions to write to CloudWatch Logs
    Properties:
      FunctionName: !Sub set-default-launch-template-${ResourceSuffix}
      Description: Do Not Modify or Delete.
      Handler: index.lambda_handler
      Runtime: python3.11
      Role: !GetAtt SetDefaultLaunchTemplateLambdaFunctionRole.Arn
      Timeout: 120
      LoggingConfig:
        LogGroup: !Ref SetDefaultLaunchTemplateLambdaFunctionLogGroup
      ReservedConcurrentExecutions: 1
      Code:
        ZipFile: !Sub |
          import json
          import logging
          import os

          import boto3  # type: ignore
          import cfnresponse  # type: ignore
          from botocore.config import Config  # type: ignore

          region = os.environ["AWS_REGION"]
          config = Config(retries={"max_attempts": 5, "mode": "standard"})
          AUTO_SCALING = boto3.client("autoscaling", region_name=region, config=config)

          CUSTOM_RESOURCE_PHYSICAL_ID = "Set_Default_LaunchTemplate_${ResourceSuffix}"

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)


          def lambda_handler(event, context):
              logger.info(f"Event: {json.dumps(event, default=str)}")

              try:
                  if event["RequestType"] == "Delete":
                      # Do not do anything on Delete
                      cfnresponse.send(event, context, cfnresponse.SUCCESS,
                                      {}, physicalResourceId=CUSTOM_RESOURCE_PHYSICAL_ID)
                      return

                  resource_properties = event["ResourceProperties"]
                  asg_name: str = resource_properties["AutoScalingGroupname"]
                  launch_template_id: str = resource_properties["LaunchTemplateId"]
                  update_auto_scaling_group(asg_name, launch_template_id)
                  cfnresponse.send(event, context, cfnresponse.SUCCESS,
                                  {}, physicalResourceId=CUSTOM_RESOURCE_PHYSICAL_ID)

              except Exception as e:
                  logger.exception(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED,
                                  {}, physicalResourceId=CUSTOM_RESOURCE_PHYSICAL_ID, reason=str(e))


          def update_auto_scaling_group(asg_name: str, launch_template_id: str):
              AUTO_SCALING.update_auto_scaling_group(
                  AutoScalingGroupName=asg_name,
                  LaunchTemplate={
                      "LaunchTemplateId": launch_template_id,
                      "Version": "$Default"
                  },
              )

  SetDefaultLaunchTemplateLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName: !Sub /aws/lambda/set-default-launch-template-${ResourceSuffix}
      RetentionInDays: 90
      # KmsKeyId: !GetAtt KmsKey.Arn

  SetDefaultLaunchTemplateLambdaFunctionRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: An explicit name is required
      checkov:
        skip:
          - id: CKV_AWS_111 # Ensure IAM policies does not allow write access without constraints
            comment: Permission policy set up to allow logging, which mirrors AWSLambdaBasicExecutionRole policy
    Properties:
      RoleName: !Sub ${IamPrefix}-SetDefaultLaunchTemplate-${ResourceSuffix}
      PermissionsBoundary: !Ref PermissionsBoundaryPolicyArn
      Description: Do Not Modify or Delete.
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
      Policies:
        - PolicyName: AllowLogging
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !GetAtt SetDefaultLaunchTemplateLambdaFunctionLogGroup.Arn
        - PolicyName: AllowAutoScalingGroupUpdate
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: autoscaling:UpdateAutoScalingGroup
                Resource: !Sub arn:${AWS::Partition}:autoscaling:${AWS::Region}:${AWS::AccountId}:autoScalingGroup:*:autoScalingGroupName/${PipelineAutoScalingGroup}
              - Effect: Allow
                Action: iam:PassRole
                Resource: !GetAtt Ec2ScannerRole.Arn
                Condition:
                  StringEquals:
                    iam:PassedToService: ec2.amazonaws.com
              - Effect: Allow
                Action:
                  - ec2:RunInstances
                  - ec2:CreateTags
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:*:image/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:instance/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:subnet/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:volume/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:network-interface/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:launch-template/${AutoScalingGroupLaunchTemplate}
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:security-group/${AvScanSecurityGroup}

  AvScanSqsQueueSizeAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      ActionsEnabled: true
      AlarmActions:
        - !Ref AsgScaleUpAction
      OKActions:
        - !Ref AsgScaleDownAction
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: QueueName
          Value:
            Fn::ImportValue: !Sub aftac-pipeline-av-scan-queue-name-${ResourceSuffix}
      EvaluationPeriods: 1
      MetricName: ApproximateNumberOfMessagesVisible
      Namespace: AWS/SQS
      Period: 120
      Statistic: Average
      Threshold: 50

  # TODO: Implement a way to replay messages in DLQ
  TransferDlq:
    Type: AWS::SQS::Queue
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      MessageRetentionPeriod: 1209600 # 14 days
      ReceiveMessageWaitTimeSeconds: 20
      KmsMasterKeyId: alias/aws/sqs

  FailedTransferTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: FailedTransferTopic
      KmsMasterKeyId: alias/aws/sns

  TransferResultEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      EventSourceArn: !GetAtt TransferResultQueue.Arn
      FunctionName: !Ref TransferResultLambda

  TransferQueue:
    Type: AWS::SQS::Queue
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      MessageRetentionPeriod: 345600 # Default value (4 days)
      ReceiveMessageWaitTimeSeconds: 20
      # KmsMasterKeyId: alias/aws/sqs
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt TransferDlq.Arn
        maxReceiveCount: 1

  TransferQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal: "*"
            Action: sqs:*
            Resource: !GetAtt TransferQueue.Arn
            Condition:
              Bool:
                aws:SecureTransport: false
          - Effect: Allow
            Principal:
              Service: s3.amazonaws.com
            Action: sqs:SendMessage
            Resource: !GetAtt TransferQueue.Arn
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
              ArnLike:
                aws:SourceArn: !Sub arn:${AWS::Partition}:s3:::*
          - Effect: Allow
            Principal:
              AWS: !Ref DiodeAccountId
            Action:
              - sqs:ReceiveMessage
              - sqs:DeleteMessage
              - sqs:GetQueueAttributes
            Resource: !GetAtt TransferQueue.Arn
            Condition:
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${DiodeAccountId}:role/${IamPrefix}-DataTransferLambdaRole-${ResourceSuffix}
      Queues:
        - !Ref TransferQueue

  TransferResultQueue:
    Type: AWS::SQS::Queue
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      MessageRetentionPeriod: 345600 # Default value (4 days)
      ReceiveMessageWaitTimeSeconds: 20
      # KmsMasterKeyId: alias/aws/sqs
      # RedrivePolicy:
      #   deadLetterTargetArn: String
      #   maxReceiveCount: 1

  TransferResultQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal: "*"
            Action: sqs:*
            Resource: !GetAtt TransferResultQueue.Arn
            Condition:
              Bool:
                aws:SecureTransport: false
          - Effect: Allow
            Principal:
              AWS: !Ref DiodeAccountId
            Action: sqs:SendMessage
            Resource: !GetAtt TransferResultQueue.Arn
            Condition:
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${DiodeAccountId}:role/${IamPrefix}-DataTransferLambdaRole-${ResourceSuffix}
      Queues:
        - !Ref TransferResultQueue

  TransferStatusTable:
    Type: AWS::DynamoDB::Table
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      BillingMode: PAY_PER_REQUEST # On-Demand Mode, for unpredictable workloads
      SSESpecification:
        SSEEnabled: true
      ### AttributeDefinitions need to include all attributes that describe the key schema for the table and indexes
      AttributeDefinitions:
        - AttributeName: s3Key
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: S
        - AttributeName: mappingId
          AttributeType: S
        - AttributeName: status
          AttributeType: S
      KeySchema:
        - AttributeName: s3Key
          KeyType: HASH # partition key
        - AttributeName: timestamp
          KeyType: RANGE # sort key
      GlobalSecondaryIndexes:
        - IndexName: mappingId-index
          KeySchema:
            - AttributeName: mappingId
              KeyType: HASH # partition key
            - AttributeName: status
              KeyType: RANGE # sort key
          Projection:
            NonKeyAttributes:
              - s3Key
              - subject
              - errorMessage
              - govPoc
              - dataOwner
              - keyOwner
            ProjectionType: INCLUDE
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: true

  ApprovedFileTypesParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/ApprovedFileTypes-${ResourceSuffix}
      Description: Filetypes which are authorized for low to high transfer
      Type: StringList
      Value: !Ref ApprovedFileTypes

  DfdlApprovedFileTypesParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/DfdlApprovedFileTypes-${ResourceSuffix}
      Description: Filetypes which are authorized for low to high transfer after DFDL Conversion
      Type: StringList
      Value: !Ref DfdlApprovedFileTypes

  InvalidFilesBucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/InvalidFilesBucketName-${ResourceSuffix}
      Description: Name of the Bucket where files which fail content-type validation are stored
      Type: String
      Value: !Ref InvalidFilesBucket

  InvalidFilesTopicArnParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/InvalidFilesTopicArn-${ResourceSuffix}
      Description: ARN of the SNS Topic where files which fail content-type validation are published to.
      Type: String
      Value: !GetAtt InvalidFilesTopic.TopicArn

  DataTransferIngestBucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/DataTransferIngestBucketName-${ResourceSuffix}
      Description: Name of the bucket where files are staged for diode processing
      Type: String
      Value: !Ref DataTransferBucket

  QuarantineBucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/QuarantineBucketName-${ResourceSuffix}
      Description: Name of the Bucket where files which are deemed to potentially contain malware are stored
      Type: String
      Value: !Ref QuarantineBucket

  QuarantineTopicARNParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/QuarantineTopicArn-${ResourceSuffix}
      Description: ARN of the SNS Topic where files which are deemed to potentially contain malware are published to.
      Type: String
      Value: !GetAtt InfectedFileTopic.TopicArn

Outputs:
  DataTransferBucketName:
    Description: Data Transfer Bucket Name
    Value: !Ref DataTransferBucket

  DataTransferSqsQueueArn:
    Description: Data Transfer SQS Queue ARN
    Value: !GetAtt TransferQueue.Arn

  DataTransferResultSqsQueueArn:
    Description: Data Transfer Result SQS Queue ARN
    Value: !GetAtt TransferResultQueue.Arn

  PipelineAutoScalingGroupName:
    Description: Pipeline AutoScaling Group Name
    Value: !Ref PipelineAutoScalingGroup
    Export:
      Name: !Sub aftac-pipeline-asg-name-${ResourceSuffix}
