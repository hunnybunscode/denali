Parameters:
  IamPrefix:
    Type: String
    Description: Prefix added to all IAM resources

  PermissionsBoundaryPolicyArn:
    Type: String
    Description: ARN of the policy that is used to set the permissions boundary for IAM resources

  ResourceSuffix:
    Type: String
    Description: Suffix added to the named AWS resources

  VpcId:
    Type: String
    Description: The VPC ID to use for the pipeline

  VpcCidr:
    Type: String
    Description: The CIDR block of the existing VPC

  PrivateSubnetIds:
    Type: CommaDelimitedList
    Description: The list of private subnet IDs to use for the pipeline

  S3PrefixListId:
    Type: String
    Description: The S3 prefix list ID to use for the pipeline

  DDBPrefixListId:
    Type: String
    Description: The DDB prefix list ID to use for the pipeline

  PipelineAmiId:
    Type: AWS::EC2::Image::Id
    Description: The AMI ID to use for the pipeline
    AllowedPattern: ^ami-[0-9a-f]{17}$
    ConstraintDescription: Must be a valid AMI ID

  DfdlApprovedFileTypes:
    Type: String
    Description: The list of approved file types for DFDL

  ExemptFileTypes:
    Type: String
    Description: The list of exempt file types

  EmailEndPoint:
    Type: String
    Description: The email address to use for SNS notifications

  IngestKmsKeyArn:
    Type: String
    Description: The ARN of the KMS key encrypting the resources in Ingest Stack

  DiodeAccountId:
    Type: String
    Description: AWS Account ID of the Diode Account
    AllowedPattern: ^\d{12}$
    ConstraintDescription: Must be a valid AWS Account ID

  DiodeSimulatorInstanceRole:
    Type: String
    Description: ARN of the IAM role associated with the Diode Simulator instance profile

  SsmAgentUpdateInterval:
    Type: String
    Description: Determines whether and when the SSM Agent is updated on EC2 scanner instances.

  MaxConcurrency:
    Type: String
    Description: The maximum number of EC2 scanner instances, in percentage, on which to update SSM Agent at the same time.

  MaxErrors:
    Type: String
    Description: Maximum allowable error percentage before aborting the SSM Agent update process.

  TranstionToGlacierIR:
    Type: Number
    Description: Enter the number of days after which to transition to Glacier Instant Retrieval (IR) storage class.

  TransitionToDeepArchive:
    Type: Number
    Description: Enter the number of days after which to transition to Deep Archive storage class. Must be at least 90 days after Glacier IR transition.

  InvalidFilesBucketExpirationInDays:
    Type: Number
    Description: Enter the number of days you want to keep objects in the INVALID FILES Bucket.

  FailedTransferBucketExpirationInDays:
    Type: Number
    Description: Enter the number of days you want to keep objects in the FAILED TRANSFER Bucket.

  DataTransferBucketExpirationInDays:
    Type: Number
    Description: Enter the number of days you want to keep objects in the DATA TRANSFER Bucket.

  DfdlInputBucketExpirationInDays:
    Type: Number
    Description: Enter the number of days you want to keep objects in the Dfdl Input Bucket.

  AccessLogBucketName:
    Type: String
    Description: The name of the access log bucket.

  AvScanQueueName:
    Type: String
    Description: The name of the AV Scan Queue.

  AvScanQueueUrl:
    Type: String
    Description: The URL of the AV Scan Queue.

  AvScanQueueArn:
    Type: String
    Description: The ARN of the AV Scan Queue.

  AvScanDeadLetterQueueName:
    Type: String
    Description: The name of the AV Scan Dead Letter Queue.

  AvScanDeadLetterQueueUrl:
    Type: String
    Description: The URL of the AV Scan Dead Letter Queue.

  AvScanDeadLetterQueueArn:
    Type: String
    Description: The ARN of the AV Scan Dead Letter Queue.

  TransferQueueThreshold:
    Type: Number
    Description: Alert threshold for Transfer Queue

  ResultQueueThreshold:
    Type: Number
    Description: Alert threshold for Result Queue

  AvScanQueueThreshold:
    Type: Number
    Description: Alert threshold for AV Scan Queue

  QueueMonitoringInterval:
    Type: String
    Description: How frequently to check SQS Queue metrics (in minutes)

Conditions:
  UseDiodeSimulator: !Not [!Equals [!Ref DiodeSimulatorInstanceRole, ""]]
  SendEmailNotifications: !Not [!Equals [!Ref EmailEndPoint, ""]]
  ExemptFileTypesBlank: !Equals [!Ref ExemptFileTypes, ""]

Resources:
  PipelineKmsKey:
    Type: AWS::KMS::Key
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      Description: KMS key for pipeline
      Enabled: true
      EnableKeyRotation: true
      PendingWindowInDays: 30
      KeyPolicy:
        Version: 2012-10-17
        Statement:
          - Sid: Allow administration of the key via IAM policies
            Effect: Allow
            Principal:
              AWS: !Ref AWS::AccountId
            NotAction:
              - kms:Encrypt
              - kms:Decrypt
              - kms:ReEncrypt*
              - kms:GenerateDataKey*
              - kms:CreateGrant
            Resource: "*"
          - Sid: Allow cryptographic operations via IAM policies
            Effect: Allow
            Principal:
              AWS: !Ref AWS::AccountId
            Action:
              - kms:Decrypt
              - kms:GenerateDataKey
            Resource: "*"
            Condition:
              StringEquals:
                kms:ViaService:
                  - !Sub s3.${AWS::Region}.amazonaws.com
                  - !Sub sqs.${AWS::Region}.amazonaws.com
          - Sid: Allow EC2 scanner role to encrypt
            Effect: Allow
            Principal:
              AWS: !GetAtt Ec2ScannerRole.Arn
            Action:
              - kms:GenerateDataKey
              - kms:Decrypt
            Resource: "*"
            Condition:
              StringEquals:
                kms:ViaService: !Sub s3.${AWS::Region}.amazonaws.com
          - Sid: Allow Transfer Result Lambda execution role to encrypt and decrypt
            Effect: Allow
            Principal:
              AWS: !GetAtt TransferResultLambdaRole.Arn
            Action:
              - kms:GenerateDataKey
              - kms:Decrypt
            Resource: "*"
            Condition:
              StringEquals:
                kms:ViaService:
                  - !Sub s3.${AWS::Region}.amazonaws.com
                  - !Sub sqs.${AWS::Region}.amazonaws.com
          - Sid: Allow Data Transfer Lambda execution role to decrypt
            Effect: Allow
            Principal:
              AWS: !Ref DiodeAccountId
            Action:
              - kms:GenerateDataKey
              - kms:Decrypt
            Resource: "*"
            Condition:
              StringEquals:
                kms:ViaService:
                  - !Sub s3.${AWS::Region}.amazonaws.com
                  - !Sub sqs.${AWS::Region}.amazonaws.com
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${DiodeAccountId}:role/${IamPrefix}-DataTransferLambdaRole-${ResourceSuffix}

  PipelineKmsKeyAlias:
    Type: AWS::KMS::Alias
    Properties:
      AliasName: !Sub alias/pipeline-stack-${ResourceSuffix}
      TargetKeyId: !Ref PipelineKmsKey

  Ec2ScannerRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: An explicit name is required
    Properties:
      # Note that there is a dependency on this name
      RoleName: !Sub ${IamPrefix}-Ec2ScannerRole-${ResourceSuffix}
      PermissionsBoundary: !Ref PermissionsBoundaryPolicyArn
      Description: Role to be assumed by EC2 Anti-Virus Scanner instances
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/AmazonSSMManagedInstanceCore
      Policies:
        - PolicyName: CwLogsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:DescribeLogStreams
                  - logs:PutLogEvents
                  - logs:PutRetentionPolicy
                  - cloudwatch:PutMetricData
                Effect: Allow
                Resource: "*"
        - PolicyName: SqsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - sqs:DeleteMessage
                  - sqs:ReceiveMessage
                  - sqs:SendMessage
                  - sqs:ChangeMessageVisibility
                Resource: !Sub arn:${AWS::Partition}:sqs:${AWS::Region}:${AWS::AccountId}:*
        - PolicyName: S3Policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - s3:DeleteObject
                  - s3:GetBucketAcl
                  - s3:GetObject
                  - s3:GetObjectTagging
                  - s3:ListBucket
                  - s3:PutObject
                  - s3:PutObjectTagging
                  - s3:GetBucketTagging
                Resource: "*"
                Condition:
                  StringEquals:
                    s3:ResourceAccount: !Ref AWS::AccountId
        - PolicyName: SnsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: sns:Publish
                Resource: "*"
        - PolicyName: Ec2Policy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: ec2:DescribeTags
                Resource: "*"
        - PolicyName: KmsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: kms:Decrypt
                Resource: !Ref IngestKmsKeyArn
        - PolicyName: Ec2AutoScalingPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: autoscaling:SetInstanceHealth
                Resource: "*" # Can't reference the auto scaling group ARN due to a circular dependency
                Condition:
                  StringEquals:
                    aws:ResourceAccount: !Ref AWS::AccountId
                    aws:RequestedRegion: !Ref AWS::Region

  Ec2ScannerInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      InstanceProfileName: !Sub ${IamPrefix}-Ec2ScannerInstanceProfile-${ResourceSuffix}
      Roles: [!Ref Ec2ScannerRole]

  TransferResultLambdaRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: An explicit name is required
    Properties:
      RoleName: !Sub ${IamPrefix}-TransferResultLambdaRole-${ResourceSuffix}
      PermissionsBoundary: !Ref PermissionsBoundaryPolicyArn
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: TransferResultLambdaRoleDefaultPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              # Security best practice: https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html#configuration-vpc-best-practice-security
              - Effect: Deny
                Action:
                  - ec2:CreateNetworkInterface
                  - ec2:DeleteNetworkInterface
                  - ec2:DescribeNetworkInterfaces
                  - ec2:DescribeSubnets
                  - ec2:DetachNetworkInterface
                  - ec2:AssignPrivateIpAddresses
                  - ec2:UnassignPrivateIpAddresses
                Resource: "*"
                Condition:
                  ArnEquals:
                    lambda:SourceFunctionArn: !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:${AWS::AccountId}:function:transfer-result-recorder-${ResourceSuffix}
              - Effect: Allow
                Action:
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                  - sqs:ReceiveMessage
                Resource: !Sub arn:${AWS::Partition}:sqs:${AWS::Region}:${AWS::AccountId}:*
              - Effect: Allow
                Action: sns:Publish
                Resource: !Ref FailedTransferTopic
              - Effect: Allow
                Action: dynamodb:PutItem
                Resource: !GetAtt TransferStatusTable.Arn
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:GetObjectTagging
                  - s3:PutObject
                  - s3:PutObjectTagging
                  - s3:DeleteObject
                  - s3:GetBucketAcl
                  - s3:ListBucket
                Resource: !Sub arn:${AWS::Partition}:s3:::*

  TransferResultLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W58 # Lambda functions require permission to write CloudWatch Logs
            reason: The managed policy, AWSLambdaVPCAccessExecutionRole, attached to the execution role includes permissions to write to CloudWatch Logs
    Properties:
      FunctionName: !Sub transfer-result-recorder-${ResourceSuffix}
      Handler: index.lambda_handler
      Role: !GetAtt TransferResultLambdaRole.Arn
      Runtime: python3.11
      Timeout: 15
      # LoggingConfig:
      #   LogGroup: The name of the log group
      # ReservedConcurrentExecutions: 50
      Environment:
        Variables:
          QUEUE_URL: !Ref TransferResultQueue
          FAILED_TRANSFER_TOPIC_ARN: !Ref FailedTransferTopic
          DATA_TRANSFER_BUCKET: !Ref DataTransferBucket
          DYNAMODB_TABLE_NAME: !Ref TransferStatusTable
          FAILED_TRANSFER_BUCKET: !Ref FailedTransferBucket
          ACCOUNT_ID: !Ref AWS::AccountId
      VpcConfig:
        SecurityGroupIds:
          - !Ref LambdaFunctionsSecurityGroup
        SubnetIds: !Ref PrivateSubnetIds
      Code:
        ZipFile: |
          import json
          import logging
          import os
          import zoneinfo
          from datetime import datetime

          import boto3  # type: ignore
          from botocore.config import Config  # type: ignore
          from botocore.exceptions import ClientError  # type: ignore

          QUEUE_URL = os.environ["QUEUE_URL"]

          DATA_TRANSFER_BUCKET = os.environ["DATA_TRANSFER_BUCKET"]
          FAILED_TRANSFER_BUCKET = os.environ["FAILED_TRANSFER_BUCKET"]

          DDB_TABLE_NAME = os.environ["DYNAMODB_TABLE_NAME"]
          FAILED_TRANSFER_TOPIC_ARN = os.environ["FAILED_TRANSFER_TOPIC_ARN"]
          ACCOUNT_ID = os.environ["ACCOUNT_ID"]

          SUCCEEDED = "SUCCEEDED"
          DATA_TAG_KEY = "DataOwner / DataSteward / GovPOC / KeyOwner"
          UNKNOWNS = ["Unknown"] * 4

          config = Config(retries={"max_attempts": 5, "mode": "standard"})
          DDB_CLIENT = boto3.client("dynamodb", config=config)
          S3_CLIENT = boto3.client("s3", config=config)
          SNS_CLIENT = boto3.client("sns", config=config)
          SQS_CLIENT = boto3.client("sqs", config=config)

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)


          def lambda_handler(event, context):
              logger.info(f"Event: {json.dumps(event, default=str)}")

              message = event["Records"][0]
              # SentTimestamp is in the epoch time in milliseconds
              timestamp = int(message["attributes"]["SentTimestamp"]) / 1000
              receipt_handle = message["receiptHandle"]
              data = json.loads(message["body"])
              # bucket = data["bucket"]
              key = data["key"]
              status = data["status"]

              try:
                  # TODO: Get the tags passed from the message
                  data_tag_values = get_data_tag_values(key)
              except ClientError as e:
                  error_code = e.response["Error"]["Code"]
                  # MethodNotAllowed error can be raised against a delete marker
                  if error_code in ("404", "NoSuchKey") or (
                      error_code == "MethodNotAllowed" and not object_exists(key)
                  ):
                      logger.warning(f"{key} not found")
                      delete_sqs_message(receipt_handle)
                      return
                  raise

              put_item_in_ddb(timestamp, data, *data_tag_values)

              if status != SUCCEEDED:
                  logger.warning(f"Data transfer failed for {key}")
                  copy_object_to_failed_transfer_bucket(key)
                  send_sns_notification_on_failed_transfer(key)

              # Delete it from the transfer bucket whether the transfer was successful or not
              delete_object_from_transfer_bucket(key)

              delete_sqs_message(receipt_handle)


          def copy_object_to_failed_transfer_bucket(key: str):
              logger.info(
                  f"Copying {key} from {DATA_TRANSFER_BUCKET} to {FAILED_TRANSFER_BUCKET}",
              )
              try:
                  S3_CLIENT.copy_object(
                      # Source bucket/key/owner
                      CopySource={"Bucket": DATA_TRANSFER_BUCKET, "Key": key},
                      ExpectedSourceBucketOwner=ACCOUNT_ID,
                      # Destination bucket/key/owner
                      Bucket=FAILED_TRANSFER_BUCKET,
                      Key=key,
                      ExpectedBucketOwner=ACCOUNT_ID,
                  )
              except ClientError as e:
                  if e.response["Error"]["Code"] in ("404", "NoSuchKey"):
                      logger.warning(f"{key} not found")
                      return
                  raise


          def send_sns_notification_on_failed_transfer(key: str):
              logger.info("Sending an SNS message regarding the failed transfer")
              SNS_CLIENT.publish(
                  TopicArn=FAILED_TRANSFER_TOPIC_ARN,
                  Subject="Failed Cross Domain Transfer",
                  Message=(
                      f"The file, {key}, was NOT successfully transferred.\n"
                      f"It has been saved in the Failed Transfer Bucket: {FAILED_TRANSFER_BUCKET}"
                  ),
              )


          def delete_object_from_transfer_bucket(key: str):
              logger.info(f"Deleting {DATA_TRANSFER_BUCKET}/{key}")
              try:
                  S3_CLIENT.delete_object(
                      Bucket=DATA_TRANSFER_BUCKET,
                      Key=key,
                      ExpectedBucketOwner=ACCOUNT_ID,
                  )
              except ClientError as e:
                  if e.response["Error"]["Code"] in ("404", "NoSuchKey"):
                      logger.warning(f"{key} not found")
                      return
                  raise


          def get_data_tag_values(key: str) -> list[str]:
              """
              Returns values for tag key `DataOwner / DataSteward / GovPOC / KeyOwner`
              as individual values in a list.\n
              If the tag is not set, returns "Unknown" x 4 in a list.
              """
              logger.info(f"Getting tags for {key}")
              tags = get_object_tags(key)
              data_tag_value = tags.get(DATA_TAG_KEY)
              if data_tag_value is None:
                  logger.warning(f"The object did not have {DATA_TAG_KEY} tag key")
                  return UNKNOWNS
              logger.info("Successfully retrieved the data tag value")
              return [tag.strip() for tag in data_tag_value.split("/")]


          def get_object_tags(key: str) -> dict[str, str]:
              """
              Returns `TagSet` for `key` in `bucket` in a dict.
              """
              tag_set = S3_CLIENT.get_object_tagging(
                  Bucket=DATA_TRANSFER_BUCKET,
                  Key=key,
                  ExpectedBucketOwner=ACCOUNT_ID,
              )["TagSet"]

              tags = {tag["Key"]: tag["Value"] for tag in tag_set}
              logger.info(f"Tags for {key}: {tags}")
              return tags


          def object_exists(key: str) -> bool:
              # When an object does not exist:
              # With ListBucket permission on the bucket, Amazon S3 returns 404 Not Found error.
              # Without ListBucket permission, Amazon S3 returns 403 Forbidden error.

              try:
                  S3_CLIENT.head_object(
                      Bucket=DATA_TRANSFER_BUCKET,
                      Key=key,
                      ExpectedBucketOwner=ACCOUNT_ID,
                  )
                  return True
              except ClientError as e:
                  if e.response["Error"]["Code"] in ("404", "NoSuchKey"):
                      logger.warning(f"{key} not found")
                      return False
                  raise


          def delete_sqs_message(receipt_handle: str):
              logger.info("Deleting message from the queue")
              SQS_CLIENT.delete_message(QueueUrl=QUEUE_URL, ReceiptHandle=receipt_handle)


          def put_item_in_ddb(
              timestamp: float,
              data: dict,
              data_owner: str,
              data_steward: str,
              gov_poc: str,
              key_owner: str,
          ):
              s3_key = data["key"]
              logger.info(f"Adding an entry into DynamoDB on the transfer status of {s3_key}")
              DDB_CLIENT.put_item(
                  TableName=DDB_TABLE_NAME,
                  Item={
                      "s3Key": {"S": s3_key},  # partition key
                      "timestamp": {
                          "S": str(
                              datetime.fromtimestamp(
                                  timestamp,
                                  zoneinfo.ZoneInfo("America/New_York"),  # sort key
                              ),
                          ),
                      },
                      "mappingId": {"S": data["mappingId"]},
                      "status": {"S": data["status"]},
                      "transferId": {"S": data["transferId"]},
                      "error": {"S": data["error"]},
                      "dataOwner": {"S": data_owner},
                      "dataSteward": {"S": data_steward},
                      "govPoc": {"S": gov_poc},
                      "keyOwner": {"S": key_owner},
                  },
              )
              logger.info("Successfully added the entry")

  QuarantineBucket:
    Type: AWS::S3::Bucket
    Metadata:
      checkov:
        skip:
          - id: CKV_AWS_21 # Ensure the S3 bucket has versioning enabled
            comment: Versioning not enabled intentionally
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      LoggingConfiguration:
        DestinationBucketName: !Ref AccessLogBucketName
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !GetAtt PipelineKmsKey.Arn
            BucketKeyEnabled: true
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: ExpiredObjectDeleteMarkerLifecycleRule
            Status: Enabled
            ExpiredObjectDeleteMarker: true

  QuarantineBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref QuarantineBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal:
              AWS: "*"
            Action: s3:*
            Resource:
              - !Sub ${QuarantineBucket.Arn}
              - !Sub ${QuarantineBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false

  InvalidFilesBucket:
    Type: AWS::S3::Bucket
    Metadata:
      checkov:
        skip:
          - id: CKV_AWS_21 # Ensure the S3 bucket has versioning enabled
            comment: Versioning not enabled intentionally
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !GetAtt PipelineKmsKey.Arn
            BucketKeyEnabled: true
      LoggingConfiguration:
        DestinationBucketName: !Ref AccessLogBucketName
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: LifeCycleRule-1
            Status: Enabled
            Transitions:
              - TransitionInDays: !Ref TranstionToGlacierIR
                StorageClass: GLACIER_IR
              - TransitionInDays: !Ref TransitionToDeepArchive
                StorageClass: DEEP_ARCHIVE
            ExpirationInDays: !Ref InvalidFilesBucketExpirationInDays
            NoncurrentVersionExpiration:
              NoncurrentDays: 1
          - Id: ExpiredObjectDeleteMarkerLifecycleRule
            Status: Enabled
            ExpiredObjectDeleteMarker: true

  InvalidFilesBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref InvalidFilesBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal:
              AWS: "*"
            Action: s3:*
            Resource:
              - !Sub ${InvalidFilesBucket.Arn}
              - !Sub ${InvalidFilesBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false

  FailedTransferBucket:
    Type: AWS::S3::Bucket
    Metadata:
      checkov:
        skip:
          - id: CKV_AWS_21 # Ensure the S3 bucket has versioning enabled
            comment: Versioning not enabled intentionally
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !GetAtt PipelineKmsKey.Arn
            BucketKeyEnabled: true
      LoggingConfiguration:
        DestinationBucketName: !Ref AccessLogBucketName
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: LifeCycleRule-1
            Status: Enabled
            Transitions:
              - TransitionInDays: !Ref TranstionToGlacierIR
                StorageClass: GLACIER_IR
              - TransitionInDays: !Ref TransitionToDeepArchive
                StorageClass: DEEP_ARCHIVE
            ExpirationInDays: !Ref FailedTransferBucketExpirationInDays
            NoncurrentVersionExpiration:
              NoncurrentDays: 1
          - Id: ExpiredObjectDeleteMarkerLifecycleRule
            Status: Enabled
            ExpiredObjectDeleteMarker: true

  FailedTransferBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref FailedTransferBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal:
              AWS: "*"
            Action: s3:*
            Resource:
              - !Sub ${FailedTransferBucket.Arn}
              - !Sub ${FailedTransferBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false

  DataTransferBucket:
    Type: AWS::S3::Bucket
    Metadata:
      checkov:
        skip:
          - id: CKV_AWS_21 # Ensure the S3 bucket has versioning enabled
            comment: Versioning not enabled intentionally
    DependsOn: TransferQueuePolicy
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !GetAtt PipelineKmsKey.Arn
            BucketKeyEnabled: true
      LoggingConfiguration:
        DestinationBucketName: !Ref AccessLogBucketName
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      NotificationConfiguration:
        QueueConfigurations:
          - Event: s3:ObjectCreated:*
            Queue: !GetAtt TransferQueue.Arn
      LifecycleConfiguration:
        Rules:
          - Id: LifeCycleRule-1
            Status: Enabled
            Transitions:
              - TransitionInDays: !Ref TranstionToGlacierIR
                StorageClass: GLACIER_IR
              - TransitionInDays: !Ref TransitionToDeepArchive
                StorageClass: DEEP_ARCHIVE
            ExpirationInDays: !Ref DataTransferBucketExpirationInDays
            NoncurrentVersionExpiration:
              NoncurrentDays: 1
          - Id: ExpiredObjectDeleteMarkerLifecycleRule
            Status: Enabled
            ExpiredObjectDeleteMarker: true

  DataTransferBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref DataTransferBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal: "*"
            Action: s3:*
            Resource:
              - !Sub ${DataTransferBucket.Arn}
              - !Sub ${DataTransferBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false
          - Effect: Allow
            Principal:
              AWS: !Ref DiodeAccountId
            Action:
              - s3:GetObject
              - s3:GetObjectTagging
              - s3:ListBucket
            Resource:
              - !Sub ${DataTransferBucket.Arn}
              - !Sub ${DataTransferBucket.Arn}/*
            Condition:
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${DiodeAccountId}:role/${IamPrefix}-DataTransferLambdaRole-${ResourceSuffix}
          - !If
            - UseDiodeSimulator
            - Sid: AllowS3PermissionsForDiodeSimulatorInstance
              Effect: Allow
              Principal:
                AWS: !Ref DiodeSimulatorInstanceRole
              Action:
                - s3:GetObject
                - s3:GetObjectTagging
                - s3:ListBucket
              Resource:
                - !Sub ${DataTransferBucket.Arn}
                - !Sub ${DataTransferBucket.Arn}/*
            - !Ref AWS::NoValue

  DfdlInputBucket:
    Type: AWS::S3::Bucket
    Metadata:
      checkov:
        skip:
          - id: CKV_AWS_21 # Ensure the S3 bucket has versioning enabled
            comment: Versioning not enabled intentionally
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: aws:kms
              KMSMasterKeyID: !GetAtt PipelineKmsKey.Arn
            BucketKeyEnabled: true
      LoggingConfiguration:
        DestinationBucketName: !Ref AccessLogBucketName
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: LifeCycleRule-1
            Status: Enabled
            Transitions:
              - TransitionInDays: !Ref TranstionToGlacierIR
                StorageClass: GLACIER_IR
              - TransitionInDays: !Ref TransitionToDeepArchive
                StorageClass: DEEP_ARCHIVE
            ExpirationInDays: !Ref DfdlInputBucketExpirationInDays
            NoncurrentVersionExpiration:
              NoncurrentDays: 1
          - Id: ExpiredObjectDeleteMarkerLifecycleRule
            Status: Enabled
            ExpiredObjectDeleteMarker: true

  LambdaFunctionsSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security Group for Lambda Functions
      SecurityGroupEgress:
        - CidrIp: !Ref VpcCidr
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to VPC CIDR
        - DestinationPrefixListId: !Ref S3PrefixListId
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to S3 Gateway Endpoint
        - DestinationPrefixListId: !Ref DDBPrefixListId
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to DDB Gateway Endpoint
      VpcId: !Ref VpcId

  AvScanSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security Group for Pipeline EC2 instances
      SecurityGroupEgress:
        - CidrIp: !Ref VpcCidr
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to VPC CIDR
        - DestinationPrefixListId: !Ref S3PrefixListId
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          Description: Allow TCP traffic out to S3 Gateway Endpoint
      VpcId: !Ref VpcId

  InfectedFileTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Infected File SNS Topic
      KmsMasterKeyId: alias/aws/sns

  InfectedFileTopicSubscription:
    Type: AWS::SNS::Subscription
    Condition: SendEmailNotifications
    Properties:
      TopicArn: !Ref InfectedFileTopic
      Protocol: email
      Endpoint: !Ref EmailEndPoint

  InvalidFilesTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Invalid File SNS Topic
      KmsMasterKeyId: alias/aws/sns

  InvalidFilesTopicSubscription:
    Type: AWS::SNS::Subscription
    Condition: SendEmailNotifications
    Properties:
      TopicArn: !Ref InvalidFilesTopic
      Protocol: email
      Endpoint: !Ref EmailEndPoint

  AutoScalingGroupLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        IamInstanceProfile:
          Arn: !GetAtt Ec2ScannerInstanceProfile.Arn
        ImageId: !Ref PipelineAmiId
        InstanceType: m5.large
        BlockDeviceMappings:
          # TODO: Get the device name dynamically
          - DeviceName: /dev/sda1
            Ebs:
              VolumeSize: 50
              VolumeType: gp3
              # Encrypted: true
              # KmsKeyId: !Ref PipelineKmsKey
        Monitoring:
          Enabled: false
        MetadataOptions:
          HttpPutResponseHopLimit: 1
          HttpTokens: required
        SecurityGroupIds:
          - !GetAtt AvScanSecurityGroup.GroupId
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub ValidationPipeline/ValidationInstance-${ResourceSuffix}
      TagSpecifications:
        - ResourceType: launch-template
          Tags:
            - Key: Name
              Value: !Sub ValidationPipeline/LaunchTemplate-${ResourceSuffix}

  PipelineAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    UpdatePolicy:
      AutoScalingScheduledAction:
        IgnoreUnmodifiedGroupSizeProperties: true
    Properties:
      LaunchTemplate:
        LaunchTemplateId: !Ref AutoScalingGroupLaunchTemplate
        Version: !GetAtt AutoScalingGroupLaunchTemplate.DefaultVersionNumber
      MaxSize: "12"
      MinSize: "2"
      VPCZoneIdentifier: !Ref PrivateSubnetIds
      Tags:
        - Key: Name
          PropagateAtLaunch: false
          Value: !Sub ValidationPipeline/AutoScalingGroup-${ResourceSuffix}

  SsmAgentUpdateAssociation:
    Type: AWS::SSM::Association
    Properties:
      AssociationName: !Sub UpdateSSMAgent-${ResourceSuffix}
      Name: AWS-UpdateSSMAgent
      ScheduleExpression: !Ref SsmAgentUpdateInterval
      ApplyOnlyAtCronInterval: true
      MaxConcurrency: !Ref MaxConcurrency
      MaxErrors: !Ref MaxErrors
      Targets:
        - Key: tag:Name
          Values:
            - !Sub ValidationPipeline/ValidationInstance-${ResourceSuffix}

  AsgScaleUpAction:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AdjustmentType: ChangeInCapacity
      AutoScalingGroupName: !Ref PipelineAutoScalingGroup
      EstimatedInstanceWarmup: 120
      MetricAggregationType: Average
      PolicyType: StepScaling
      StepAdjustments:
        - MetricIntervalLowerBound: 0
          ScalingAdjustment: 1

  AsgScaleDownAction:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AdjustmentType: ChangeInCapacity
      AutoScalingGroupName: !Ref PipelineAutoScalingGroup
      EstimatedInstanceWarmup: 120
      MetricAggregationType: Average
      PolicyType: StepScaling
      StepAdjustments:
        - MetricIntervalUpperBound: -10
          ScalingAdjustment: -1

  SetDefaultLaunchTemplateTrigger:
    Type: Custom::SetDefaultLaunchTemplateTrigger
    Properties:
      ServiceToken: !GetAtt SetDefaultLaunchTemplateLambdaFunction.Arn
      ServiceTimeout: "120"
      AutoScalingGroupname: !Ref PipelineAutoScalingGroup
      LaunchTemplateId: !Ref AutoScalingGroupLaunchTemplate

  SetDefaultLaunchTemplateLambdaFunction:
    Type: AWS::Lambda::Function
    Metadata:
      checkov:
        skip:
          - id: CKV_AWS_116 # Ensure that AWS Lambda function is configured for a Dead Letter Queue(DLQ)
            comment: Invoked by CloudFormation, the function surfaces any errors through the stack, without the need for a DLQ
          - id: CKV_AWS_117 # Ensure that AWS Lambda function is configured inside a VPC
            comment: This function is not required to be deployed inside a VPC
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: This function is not required to be deployed inside a VPC
          - id: W58 # Lambda functions require permission to write CloudWatch Logs
            reason: The execution role includes permissions to write to CloudWatch Logs
    Properties:
      FunctionName: !Sub set-default-launch-template-${ResourceSuffix}
      Description: Do Not Modify or Delete.
      Handler: index.lambda_handler
      Runtime: python3.11
      Role: !GetAtt SetDefaultLaunchTemplateLambdaFunctionRole.Arn
      Timeout: 120
      LoggingConfig:
        LogGroup: !Ref SetDefaultLaunchTemplateLambdaFunctionLogGroup
      ReservedConcurrentExecutions: 1
      Code:
        ZipFile: !Sub |
          import json
          import logging
          import os

          import boto3  # type: ignore
          import cfnresponse  # type: ignore
          from botocore.config import Config  # type: ignore

          region = os.environ["AWS_REGION"]
          config = Config(retries={"max_attempts": 5, "mode": "standard"})
          AUTO_SCALING = boto3.client("autoscaling", region_name=region, config=config)

          CUSTOM_RESOURCE_PHYSICAL_ID = "Set_Default_LaunchTemplate_${ResourceSuffix}"

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)


          def lambda_handler(event, context):
              logger.info(f"Event: {json.dumps(event, default=str)}")

              try:
                  if event["RequestType"] == "Delete":
                      # Do not do anything on Delete
                      cfnresponse.send(event, context, cfnresponse.SUCCESS,
                                      {}, physicalResourceId=CUSTOM_RESOURCE_PHYSICAL_ID)
                      return

                  resource_properties = event["ResourceProperties"]
                  asg_name: str = resource_properties["AutoScalingGroupname"]
                  launch_template_id: str = resource_properties["LaunchTemplateId"]
                  update_auto_scaling_group(asg_name, launch_template_id)
                  cfnresponse.send(event, context, cfnresponse.SUCCESS,
                                  {}, physicalResourceId=CUSTOM_RESOURCE_PHYSICAL_ID)

              except Exception as e:
                  logger.exception(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED,
                                  {}, physicalResourceId=CUSTOM_RESOURCE_PHYSICAL_ID, reason=str(e))


          def update_auto_scaling_group(asg_name: str, launch_template_id: str):
              AUTO_SCALING.update_auto_scaling_group(
                  AutoScalingGroupName=asg_name,
                  LaunchTemplate={
                      "LaunchTemplateId": launch_template_id,
                      "Version": "$Default"
                  },
              )

  SetDefaultLaunchTemplateLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName: !Sub /aws/lambda/set-default-launch-template-${ResourceSuffix}
      RetentionInDays: 90
      # KmsKeyId: !GetAtt KmsKey.Arn

  SetDefaultLaunchTemplateLambdaFunctionRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: An explicit name is required
      checkov:
        skip:
          - id: CKV_AWS_111 # Ensure IAM policies does not allow write access without constraints
            comment: Permission policy set up to allow logging, which mirrors AWSLambdaBasicExecutionRole policy
    Properties:
      RoleName: !Sub ${IamPrefix}-SetDefaultLaunchTemplate-${ResourceSuffix}
      PermissionsBoundary: !Ref PermissionsBoundaryPolicyArn
      Description: Do Not Modify or Delete.
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
      Policies:
        - PolicyName: AllowLogging
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !GetAtt SetDefaultLaunchTemplateLambdaFunctionLogGroup.Arn
        - PolicyName: AllowAutoScalingGroupUpdate
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: autoscaling:UpdateAutoScalingGroup
                Resource: !Sub arn:${AWS::Partition}:autoscaling:${AWS::Region}:${AWS::AccountId}:autoScalingGroup:*:autoScalingGroupName/${PipelineAutoScalingGroup}
              - Effect: Allow
                Action: iam:PassRole
                Resource: !GetAtt Ec2ScannerRole.Arn
                Condition:
                  StringEquals:
                    iam:PassedToService: ec2.amazonaws.com
              - Effect: Allow
                Action:
                  - ec2:RunInstances
                  - ec2:CreateTags
                Resource:
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:*:image/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:instance/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:subnet/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:volume/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:network-interface/*
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:launch-template/${AutoScalingGroupLaunchTemplate}
                  - !Sub arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:security-group/${AvScanSecurityGroup}

  AvScanSqsQueueSizeAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      ActionsEnabled: true
      AlarmActions:
        - !Ref AsgScaleUpAction
      OKActions:
        - !Ref AsgScaleDownAction
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: QueueName
          Value: !Ref AvScanQueueName
      EvaluationPeriods: 1
      MetricName: ApproximateNumberOfMessagesVisible
      Namespace: AWS/SQS
      Period: 120
      Statistic: Average
      Threshold: 50

  # TODO: Implement a way to replay messages in DLQ
  TransferDlq:
    Type: AWS::SQS::Queue
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      MessageRetentionPeriod: 1209600 # 14 days
      ReceiveMessageWaitTimeSeconds: 20
      KmsMasterKeyId: alias/aws/sqs

  FailedTransferTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: FailedTransferTopic
      KmsMasterKeyId: alias/aws/sns

  FailedTransferTopicSubscription:
    Type: AWS::SNS::Subscription
    Condition: SendEmailNotifications
    Properties:
      TopicArn: !Ref FailedTransferTopic
      Protocol: email
      Endpoint: !Ref EmailEndPoint

  TransferResultEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 1
      Enabled: true
      EventSourceArn: !GetAtt TransferResultQueue.Arn
      FunctionName: !Ref TransferResultLambda

  TransferQueue:
    Type: AWS::SQS::Queue
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      MessageRetentionPeriod: 345600 # Default value (4 days)
      ReceiveMessageWaitTimeSeconds: 20
      # KmsMasterKeyId: alias/aws/sqs
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt TransferDlq.Arn
        maxReceiveCount: 5 # This should match the number defined in data transfer Lambda function in the Diode account

  TransferQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal: "*"
            Action: sqs:*
            Resource: !GetAtt TransferQueue.Arn
            Condition:
              Bool:
                aws:SecureTransport: false
          - Effect: Allow
            Principal:
              Service: s3.amazonaws.com
            Action: sqs:SendMessage
            Resource: !GetAtt TransferQueue.Arn
            Condition:
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
              ArnLike:
                aws:SourceArn: !Sub arn:${AWS::Partition}:s3:::*
          - Effect: Allow
            Principal:
              AWS: !Ref DiodeAccountId
            Action:
              - sqs:ReceiveMessage
              - sqs:DeleteMessage
              - sqs:GetQueueAttributes
              - sqs:ChangeMessageVisibility
            Resource: !GetAtt TransferQueue.Arn
            Condition:
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${DiodeAccountId}:role/${IamPrefix}-DataTransferLambdaRole-${ResourceSuffix}
      Queues:
        - !Ref TransferQueue

  TransferResultDlq:
    Type: AWS::SQS::Queue
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      MessageRetentionPeriod: 1209600 # 14 days
      ReceiveMessageWaitTimeSeconds: 20
      KmsMasterKeyId: alias/aws/sqs

  TransferResultQueue:
    Type: AWS::SQS::Queue
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      MessageRetentionPeriod: 345600 # Default value (4 days)
      ReceiveMessageWaitTimeSeconds: 20
      VisibilityTimeout: 30 # Default value
      KmsMasterKeyId: !GetAtt PipelineKmsKey.Arn
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt TransferResultDlq.Arn
        maxReceiveCount: 5

  TransferResultQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Deny
            Principal: "*"
            Action: sqs:*
            Resource: !GetAtt TransferResultQueue.Arn
            Condition:
              Bool:
                aws:SecureTransport: false
          - Effect: Allow
            Principal:
              AWS: !Ref DiodeAccountId
            Action: sqs:SendMessage
            Resource: !GetAtt TransferResultQueue.Arn
            Condition:
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${DiodeAccountId}:role/${IamPrefix}-DataTransferLambdaRole-${ResourceSuffix}
      Queues:
        - !Ref TransferResultQueue

  TransferStatusTable:
    Type: AWS::DynamoDB::Table
    UpdateReplacePolicy: Delete
    DeletionPolicy: Delete
    Properties:
      BillingMode: PAY_PER_REQUEST # On-Demand Mode, for unpredictable workloads
      SSESpecification:
        SSEEnabled: true
      ### AttributeDefinitions need to include all attributes that describe the key schema for the table and indexes
      AttributeDefinitions:
        - AttributeName: s3Key
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: S
        - AttributeName: mappingId
          AttributeType: S
        - AttributeName: status
          AttributeType: S
      KeySchema:
        - AttributeName: s3Key
          KeyType: HASH # partition key
        - AttributeName: timestamp
          KeyType: RANGE # sort key
      GlobalSecondaryIndexes:
        - IndexName: mappingId-index
          KeySchema:
            - AttributeName: mappingId
              KeyType: HASH # partition key
            - AttributeName: status
              KeyType: RANGE # sort key
          Projection:
            NonKeyAttributes:
              - s3Key
              - subject
              - errorMessage
              - govPoc
              - dataOwner
              - keyOwner
            ProjectionType: INCLUDE
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: true

  DfdlApprovedFileTypesParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/DfdlApprovedFileTypes-${ResourceSuffix}
      Description: File types which are authorized for low to high transfer after DFDL Conversion
      Type: StringList
      Value: !Ref DfdlApprovedFileTypes

  ExemptFileTypesParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/ExemptFileTypes-${ResourceSuffix}
      Description: File types that should bypass file type validation
      Type: StringList
      Value: !If [ExemptFileTypesBlank, " ", !Ref ExemptFileTypes]

  InvalidFilesBucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/InvalidFilesBucketName-${ResourceSuffix}
      Description: Name of the Bucket where files which fail content-type validation are stored
      Type: String
      Value: !Ref InvalidFilesBucket

  InvalidFilesTopicArnParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/InvalidFilesTopicArn-${ResourceSuffix}
      Description: ARN of the SNS Topic where files which fail content-type validation are published to.
      Type: String
      Value: !Ref InvalidFilesTopic

  DataTransferIngestBucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/DataTransferIngestBucketName-${ResourceSuffix}
      Description: Name of the bucket where files are staged for diode processing
      Type: String
      Value: !Ref DataTransferBucket

  DfdlInputBucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/DfdlInputBucketName-${ResourceSuffix}
      Description: Name of the bucket where files are staged for diode processing
      Type: String
      Value: !Ref DfdlInputBucket

  QuarantineBucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/QuarantineBucketName-${ResourceSuffix}
      Description: Name of the Bucket where files which are deemed to potentially contain malware are stored
      Type: String
      Value: !Ref QuarantineBucket

  QuarantineTopicARNParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub /pipeline/QuarantineTopicArn-${ResourceSuffix}
      Description: ARN of the SNS Topic where files which are deemed to potentially contain malware are published to.
      Type: String
      Value: !Ref InfectedFileTopic

  QueueMonitorTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Queue Monitor Alert Topic
      KmsMasterKeyId: alias/aws/sns

  QueueMonitorTopicSubscription:
    Type: AWS::SNS::Subscription
    Condition: SendEmailNotifications
    Properties:
      TopicArn: !Ref QueueMonitorTopic
      Protocol: email
      Endpoint: !Ref EmailEndPoint

  QueueMonitorDLQTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Queue Monitor DLQ Topic
      KmsMasterKeyId: alias/aws/sns

  QueueMonitorDLQTopicSubscription:
    Type: AWS::SNS::Subscription
    Condition: SendEmailNotifications
    Properties:
      TopicArn: !Ref QueueMonitorDLQTopic
      Protocol: email
      Endpoint: !Ref EmailEndPoint

  QueueMonitorLogGroup:
    Type: AWS::Logs::LogGroup
    UpdateReplacePolicy: Retain
    DeletionPolicy: Delete
    Properties:
      LogGroupName: !Sub /aws/lambda/queue-monitor-${ResourceSuffix}
      RetentionInDays: 90

  QueueMonitorRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${IamPrefix}-QueueMonitor-${ResourceSuffix}
      PermissionsBoundary: !Ref PermissionsBoundaryPolicyArn
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: AllowLogging
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !GetAtt QueueMonitorLogGroup.Arn
        - PolicyName: AllowSQSAccess
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - sqs:GetQueueAttributes
                Resource:
                  - !GetAtt TransferQueue.Arn
                  - !GetAtt TransferDlq.Arn
                  - !GetAtt TransferResultQueue.Arn
                  - !GetAtt TransferResultDlq.Arn
                  - !Ref AvScanQueueArn
                  - !Ref AvScanDeadLetterQueueArn

        - PolicyName: AllowSNSPublish
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: sns:Publish
                Resource:
                  - !Ref QueueMonitorTopic
                  - !Ref QueueMonitorDLQTopic

  QueueMonitorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub queue-monitor-${ResourceSuffix}
      Handler: index.lambda_handler
      Role: !GetAtt QueueMonitorRole.Arn
      Runtime: python3.11
      Timeout: 30
      ReservedConcurrentExecutions: 1
      DeadLetterConfig:
        TargetArn: !Ref QueueMonitorDLQTopic
      LoggingConfig:
        LogGroup: !Ref QueueMonitorLogGroup
      Environment:
        Variables:
          TOPIC_ARN: !Ref QueueMonitorTopic
          TRANSFER_QUEUE_NAME: !GetAtt TransferQueue.QueueName
          TRANSFER_DLQ_NAME: !GetAtt TransferDlq.QueueName
          TRANSFER_RESULT_QUEUE_NAME: !GetAtt TransferResultQueue.QueueName
          TRANSFER_RESULT_DLQ_NAME: !GetAtt TransferResultDlq.QueueName
          AV_SCAN_QUEUE_NAME: !Ref AvScanQueueName
          AV_SCAN_DLQ_NAME: !Ref AvScanDeadLetterQueueName
          AV_SCAN_QUEUE_URL: !Ref AvScanQueueUrl
          AV_SCAN_DLQ_URL: !Ref AvScanDeadLetterQueueUrl
          TRANSFER_QUEUE_URL: !Ref TransferQueue
          TRANSFER_DLQ_URL: !Ref TransferDlq
          RESULT_QUEUE_URL: !Ref TransferResultQueue
          RESULT_DLQ_URL: !Ref TransferResultDlq
          TRANSFER_QUEUE_THRESHOLD: !Ref TransferQueueThreshold
          RESULT_QUEUE_THRESHOLD: !Ref ResultQueueThreshold
          AV_SCAN_QUEUE_THRESHOLD: !Ref AvScanQueueThreshold
      Code:
        ZipFile: |
          import json
          import logging
          import os
          from datetime import datetime, timezone

          import boto3

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          SQS = boto3.client('sqs')
          SNS = boto3.client('sns')

          QUEUE_CONFIGS = [
              {
                  "name": os.environ['TRANSFER_QUEUE_NAME'],
                  "url": os.environ['TRANSFER_QUEUE_URL'],
                  "threshold": int(os.environ['TRANSFER_QUEUE_THRESHOLD'])
              },
              {
                  "name": os.environ['TRANSFER_DLQ_NAME'],
                  "url": os.environ['TRANSFER_DLQ_URL'],
                  "threshold": 1
              },
              {
                  "name": os.environ['TRANSFER_RESULT_QUEUE_NAME'],
                  "url": os.environ['RESULT_QUEUE_URL'],
                  "threshold": int(os.environ['RESULT_QUEUE_THRESHOLD'])
              },
              {
                  "name": os.environ['TRANSFER_RESULT_DLQ_NAME'],
                  "url": os.environ['RESULT_DLQ_URL'],
                  "threshold": 1
              },
              {
                  "name": os.environ['AV_SCAN_QUEUE_NAME'],
                  "url": os.environ['AV_SCAN_QUEUE_URL'],
                  "threshold": int(os.environ['AV_SCAN_QUEUE_THRESHOLD'])
              },
              {
                  "name": os.environ['AV_SCAN_DLQ_NAME'],
                  "url": os.environ['AV_SCAN_DLQ_URL'],
                  "threshold": 1
              }
          ]

          def check_queue(queue_config):
              try:
                  response = SQS.get_queue_attributes(
                      QueueUrl=queue_config['url'],
                      AttributeNames=['ApproximateNumberOfMessages']
                  )
                  messages = int(response['Attributes']['ApproximateNumberOfMessages'])
                  return {
                      'name': queue_config['name'],
                      'messages': messages,
                      'threshold': queue_config['threshold'],
                      'exceeds_threshold': messages > queue_config['threshold']
                  }
              except Exception as e:
                  logger.error(f"Error checking queue {queue_config['name']}: {str(e)}")
                  return None

          def lambda_handler(event, context):
              alerts = []
              error_queues = []

              for queue_config in QUEUE_CONFIGS:
                  status = check_queue(queue_config)
                  if status is None:
                      error_queues.append(queue_config['name'])
                  elif status['exceeds_threshold']:
                      alerts.append(status)

              logger.info(f"Error queues: {error_queues}")
              if error_queues:
                  message = f"Queue Error - {datetime.now(timezone.utc).isoformat()}\n\n"
                  message += "The following queue(s) could not be checked:\n\n"

                  for error_queue in error_queues:
                      message += f"Queue: {error_queue}\n\n"

                  SNS.publish(
                      TopicArn=os.environ['TOPIC_ARN'],
                      Subject="Queue Monitor Errors",
                      Message=message
                  )

              logger.info(f"Alerts: {alerts}")
              if alerts:
                  message = f"Queue Alert - {datetime.now(timezone.utc).isoformat()}\n\n"
                  message += "The following queue(s) have exceeded their thresholds:\n\n"

                  for alert in alerts:
                      message += f"Queue: {alert['name']}\n"
                      message += f"Current Messages: {alert['messages']}\n"
                      message += f"Threshold: {alert['threshold']}\n\n"

                  SNS.publish(
                      TopicArn=os.environ['TOPIC_ARN'],
                      Subject="Queue Monitor Alert",
                      Message=message
                  )

              logger.info("Lambda execution completed")

  QueueMonitorScheduleRule:
    Type: AWS::Events::Rule
    Properties:
      Description: Trigger queue monitoring Lambda function
      ScheduleExpression: !Ref QueueMonitoringInterval
      State: ENABLED
      Targets:
        - Arn: !GetAtt QueueMonitorFunction.Arn
          Id: QueueMonitorFunction

  QueueMonitorLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref QueueMonitorFunction
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt QueueMonitorScheduleRule.Arn

Outputs:
  DataTransferBucketName:
    Description: Data Transfer Bucket Name
    Value: !Ref DataTransferBucket

  DataTransferSqsQueueArn:
    Description: Data Transfer SQS Queue ARN
    Value: !GetAtt TransferQueue.Arn

  DataTransferResultSqsQueueArn:
    Description: Data Transfer Result SQS Queue ARN
    Value: !GetAtt TransferResultQueue.Arn

  DfdlInputBucketName:
    Description: Dfdl Bucket Name
    Value: !Ref DfdlInputBucket

  PipelineKmsKeyArn:
    Description: Pipeline KMS Key ARN
    Value: !GetAtt PipelineKmsKey.Arn

  PipelineAutoScalingGroupName:
    Description: Pipeline AutoScaling Group Name
    Value: !Ref PipelineAutoScalingGroup
    Export:
      Name: !Sub aftac-pipeline-asg-name-${ResourceSuffix}

  LaunchTemplateId:
    Description: Launch Template ID
    Value: !Ref AutoScalingGroupLaunchTemplate
    Export:
      Name: !Sub aftac-pipeline-launch-template-name-${ResourceSuffix}

  Ec2ScannerRoleArn:
    Description: ARN of the role used by the EC2 Scanner
    Value: !GetAtt Ec2ScannerRole.Arn
    Export:
      Name: !Sub aftac-pipeline-ec2-scanner-role-arn-${ResourceSuffix}
